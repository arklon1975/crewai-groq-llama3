{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cd35694-5f5a-4d16-8669-ec1f5bf43393",
   "metadata": {},
   "source": [
    "# A low-cost option: CrewAI with Groq, Llama3 and Mixtral"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f6660b-e894-4c8a-92c0-467a027a4100",
   "metadata": {},
   "source": [
    "## The problem and the solution\n",
    "* Problem: Multi-Agent LLM Apps are very expensive to run in OpenAI.\n",
    "* Solution: Free alternative with Groq and Llama3 or Mixtral.\n",
    "    * Not the same quality but waaaaay more cheaper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4312ba1-de37-450b-89a3-c0b21d955801",
   "metadata": {},
   "source": [
    "## Caveats\n",
    "* Keep in mind that the quality of Llama3 and Mixtral is still below the quality of ChatGPT-4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac55aba-f8c3-4cfe-8bbd-ecf279664902",
   "metadata": {},
   "source": [
    "## Process\n",
    "* Clone the code of the basic CrewAI project.\n",
    "* Change LLM to Llama3 or Mixtral with Groq."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398411fd-07b6-4882-9625-e87ec3751da2",
   "metadata": {},
   "source": [
    "## Intro to Groq\n",
    "* Groq is an AI Startup company. **It is not the same as Grok, the Open LLM from Elon Musk**.\n",
    "* It has developed a new chip call LPU (Language Processing Unit) which is specificly design to run LLMs faster and cheaper.\n",
    "* It offers a Groq Cloud where you can try OpenSource LLMs like Llama3 or Mixtral.\n",
    "* **It allows you to use Llama3 or Mixtral in your apps for free using a Groq API Key**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06a1309-a5f5-4797-aab2-e90d77c2dde5",
   "metadata": {},
   "source": [
    "## How to get a free Groq API Key\n",
    "* Login into Groq Cloud: [https://console.groq.com/login](https://console.groq.com/login)\n",
    "* Once logged in, click on API Keys (left sidebar).\n",
    "* Create a new API Key.\n",
    "* Copy the API Key and paste it in your .env file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4c154f-c329-4148-a57d-ed18fcd05d32",
   "metadata": {},
   "source": [
    "## How to install Groq in your project\n",
    "Very easy. LangChain has a module for it. We can install it the same way we install other LangChain modules, using PIP or (if we are working in a Poetry app) we can also install it using Poetry. Use one of the following options:\n",
    "* pip install langchain-groq\n",
    "* poetry add langchain-groq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819fad70-2d71-4e4a-b8a6-20285d7eb44f",
   "metadata": {},
   "source": [
    "## How to use Groq in our LangChain or CrewAI project\n",
    "Very easy. Just add the following line at the top of your file:\n",
    "* from langchain_groq import ChatGroq\n",
    "\n",
    "And then, in the code, if you want to use Llama3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ce029dd-1e8b-4b82-98f6-bf9bfd09ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatGroq(\n",
    "#     model=\"llama3-70b-8192\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3f9434-fb9f-4960-af68-55af2d86d847",
   "metadata": {},
   "source": [
    "Or if you want to use Mixtral:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2232591-6853-4840-b9d4-4b338a8d81d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatGroq(\n",
    "#     model=\"mixtral-8x7b-32768\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf1eec2-693c-4f76-9559-053cbd3ea6cf",
   "metadata": {},
   "source": [
    "## Running the app we see some interesting results before seeing a Rate Limit error message\n",
    "* Remember, we are asking the app to research a new and complex topic (Agentic Behavior). There is not much info about it online yet.\n",
    "* When using Tavily the app does not find satisfactory results online, instead of using his own knowledge on the subject (as ChatGPT-4 did), Llama3 tries using a slightly different search query with Tavily.\n",
    "* The app writes a blog post.\n",
    "* But before completing the full cycle, we see this error message:\n",
    "    * groq.RateLimitError: Error code: 429 - {'error': {'message': '**Rate limit reached** for model `llama3-70b-8192` in organization `org_01hwgcd1f3fqqr0xfmrxtyyqae` on tokens per minute (TPM): Limit 3500, Used 0, Requested ~3540. Please try again in 685.714285ms. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd7fe91-6fe8-44c7-a69a-c07919ad5461",
   "metadata": {},
   "source": [
    "## We run the app again\n",
    "* Same result: Partial results and Rate Limit error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ff8d77-eb51-403d-93ae-fa6db635b7d7",
   "metadata": {},
   "source": [
    "## Looking at LangSmith, we see a larger number of tokens used\n",
    "* Almost double than when we used ChatGPT-4\n",
    "* But it is free"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fae1dca-7761-4838-8df3-f68a74f2c1a2",
   "metadata": {},
   "source": [
    "## Let's now change the research topic for a much simpler one and see the results\n",
    "* New topic: \"Last Real Madrid - Barcelona soccer match\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5751d7-0bee-4365-9b9e-9caf5d755982",
   "metadata": {},
   "source": [
    "## Tested with ChatGPT-4, it works OK.\n",
    "* Multi-agent apps work fine with chatGPT-4 even if agent and task definitions are not very well tuned. ChatGPT-4 has an impressive reasoning level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f9a552-ae29-498d-bb25-7fdbd72ab4c9",
   "metadata": {},
   "source": [
    "## Tested with Llama3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662cbfae-420c-4021-b0be-e86ebc6542e8",
   "metadata": {},
   "source": [
    "* No luck. Same error: Rate limit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e631c1-2261-41e3-aca0-12e3e04cc557",
   "metadata": {},
   "source": [
    "## Let's try with Mixtral."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17cf242-8ea5-48e8-8174-774c6d6a5619",
   "metadata": {},
   "source": [
    "* No luck. Same error: Rate limit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cfcf91-7d54-4126-adc1-c86414a5490d",
   "metadata": {},
   "source": [
    "* Huge ammount of tokens used. Still free. We will have to fine-tune the prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3cad30-cdeb-4af5-913d-57e8d3f58e5d",
   "metadata": {},
   "source": [
    "## Our initial conclussions\n",
    "* Groq is a good way to use Llama3 and Mixtral.\n",
    "* But it is still not a good solution for multi-agent Apps:\n",
    "    * Since multi-agent apps use a lot of tokens, it is easy to hit the Rate limits of Groq.\n",
    "    * The reasoning capability of Llama3 and Mixtral is still too low compared with chatGPT-4.\n",
    "* Homework for you:\n",
    "    * Experiment using with several LLMs at the same time (example: one agent running with OpenAI, the other 3 agents running with Groq and Llama3).\n",
    "    * Keep experimenting with Groq, Llama3 and Mixtral to find better approaches for Multi-Agent LLM Apps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583dcd83-520b-4dc2-a160-1578314a847e",
   "metadata": {},
   "source": [
    "## You can take a look at Groq Rate limits here\n",
    "* https://console.groq.com/settings/limits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1856366-1944-4488-87d1-4c4e1799cd39",
   "metadata": {},
   "source": [
    "## One possible way to prevent the Rate Limit error from Groq\n",
    "* Add max_iter equal to a low number of iterations (2, 3 or 4) on every agent. For example:\n",
    "    * max_iter=2\n",
    "* Keep in mind that this fix will limit the functionality of the multi-agent app. We did not like it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c2ec0e-4daf-4fb8-9e35-d40ec8a7831a",
   "metadata": {},
   "source": [
    "## Groq pricing for projects in Production\n",
    "* [Groq pricing](https://wow.groq.com/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1308ecc-1b9b-48bc-82cb-1121e777ab5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
